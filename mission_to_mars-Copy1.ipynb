{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection\n",
    "db=client.mars_mission.db\n",
    "collection=db.mars_latest_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url of page to be scraped\n",
    "url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "response1 = requests.get(url)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'lxml'\n",
    "soup1 = BeautifulSoup(response1.text, 'lxml')\n",
    "\n",
    "# print(soup1.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "NASA's InSight Places First Instrument on Mars\n",
      "\n",
      "\n",
      "\n",
      "In deploying its first instrument onto the surface of Mars, the lander completes a major mission milestone.\n",
      "\n",
      "\n",
      "\n",
      "NASA Announces Landing Site for Mars 2020 Rover\n",
      "\n",
      "\n",
      "\n",
      "After a five-year search, NASA has chosen Jezero Crater as the landing site for its upcoming Mars 2020 rover mission.\n",
      "\n",
      "\n",
      "\n",
      "Opportunity Hunkers Down During Dust Storm\n",
      "\n",
      "\n",
      "\n",
      "It's the beginning of the end for the planet-encircling dust storm on Mars. But it could still be weeks, or even months, before skies are clear enough for NASA's Opportunity rover to recharge its batteries and phone home. \n",
      "\n",
      "\n",
      "\n",
      "NASA Finds Ancient Organic Material, Mysterious Methane on Mars\n",
      "\n",
      "\n",
      "\n",
      "NASA’s Curiosity rover has found evidence on Mars with implications for NASA’s search for life.\n",
      "\n",
      "\n",
      "\n",
      "NASA Invests in Visionary Technology \n",
      "\n",
      "\n",
      "\n",
      "NASA is investing in technology concepts, including several from JPL, that may one day be used for future space exploration missions.\n",
      "\n",
      "\n",
      "\n",
      "NASA is Ready to Study the Heart of Mars\n",
      "\n",
      "\n",
      "\n",
      "NASA is about to go on a journey to study the center of Mars.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examine the results and determine the html element that returns requested info. \n",
    "results1 = soup1.find_all('div', class_='slide')\n",
    "#    print(results)\n",
    "# A blank list to hold the headlines\n",
    "news_TList = []\n",
    "newsp_List = []\n",
    "\n",
    "# Loop through returned results\n",
    "for result in results1:\n",
    "\n",
    "    # Retrieve the mars latest news title\n",
    "    news_title = result.find('div', class_='content_title').text\n",
    "    print(news_title)\n",
    "    news_TList.append(news_title)\n",
    "\n",
    "    news_p = result.find('div',class_='rollover_description_inner').text\n",
    "    print(news_p)  \n",
    "    newsp_List.append(news_p)\n",
    "    \n",
    "                             # Access the thread's text content\n",
    "try:\n",
    "         # Access the thread with CSS selectors\n",
    "    thread = result.find('a', class_='content_title')    \n",
    "\n",
    "    # The number of comments made in the thread\n",
    "    news_p = thread.text.lstrip()\n",
    "\n",
    "    # Run if the thread has comments\n",
    "    if ( ):\n",
    "        print('\\n-----------------\\n')\n",
    "        print(news_title_text)\n",
    "        print('Comments:', )\n",
    "        print('-------------')\n",
    "        print(news_title)\n",
    "        print(news_p)\n",
    "        \n",
    "        # Dictionary to be inserted as a MongoDB document\n",
    "        post = {\n",
    "                'news_title': news_title,\n",
    "                'news_p': news_p\n",
    "            }\n",
    "\n",
    "        collection.insert_one(post)\n",
    "    \n",
    "except AttributeError as e:\n",
    "    pass\n",
    "\n",
    "#for x in range(6):\n",
    "#    print(news_TList[x])\n",
    "#    print(newsp_List[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image\n",
    "Visit the url for JPL Featured Space Image [here](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars).\n",
    "\n",
    "Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "\n",
    "find the image url to the full size `.jpg` image and save a complete url string for this image.\n",
    "```python\n",
    "# Example:\n",
    "featured_image_url = 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA16225_hires.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection\n",
    "db=client.mars_mission.db\n",
    "collection=db.jpl_space_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url of page to be scraped\n",
    "url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "response2 = requests.get(url)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'lxml'\n",
    "soup2 = BeautifulSoup(response2.text, 'html')\n",
    "#print(soup2.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars/spaceimages/images/mediumsize/PIA17550_ip.jpg\n"
     ]
    }
   ],
   "source": [
    "results2 = soup2.find_all('article', class_='carousel_item')\n",
    "\n",
    "feat_imgList=[]\n",
    "\n",
    "for result in results2:\n",
    "\n",
    "    # Retrieve the mars latest news title\n",
    "    featured_image_url = url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars' + result.a['data-fancybox-href']\n",
    "    print(featured_image_url)\n",
    "    feat_imgList.append(featured_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Weather \n",
    "* Visit the Mars Weather twitter account [here](https://twitter.com/marswxreport?lang=en) and scrape the latest Mars weather tweet from the page. Save the tweet text for the weather report as a variable called `mars_weather`.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "mars_weather = 'Sol 1801 (Aug 30, 2017), Sunny, high -21C/-5F, low -80C/-112F, pressure at 8.82 hPa, daylight 06:09-17:55'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection\n",
    "db=client.mars_mission.db\n",
    "collection=db.mars_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url of page to be scraped\n",
    "url = 'https://twitter.com/marswxreport?lang=en'\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "response3 = requests.get(url)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'lxml'\n",
    "soup3 = BeautifulSoup(response3.text, 'lxml')\n",
    "#print(soup3.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sol 2291 (2019-01-16), high -8C/17F, low -70C/-93F, pressure at 8.23 hPa, daylight 06:46-18:55pic.twitter.com/IRiqxlJqvT\n"
     ]
    }
   ],
   "source": [
    "mars_weather = soup3.find('p', class_='TweetTextSize TweetTextSize--normal js-tweet-text tweet-text').text \n",
    "print(mars_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts\n",
    "* Visit the Mars Facts webpage [here](http://space-facts.com/mars/) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "* Use Pandas to convert the data to a HTML table string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection\n",
    "db=client.mars_mission.db\n",
    "collection=db.mars_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url of page to be scraped\n",
    "url = 'http://space-facts.com/mars/'\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "response4 = requests.get(url)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'lxml'\n",
    "soup4 = BeautifulSoup(response4.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup4.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres\n",
    "\n",
    "* Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "* You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "* Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "\n",
    "* Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "hemisphere_image_urls = [\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection\n",
    "db=client.mars_mission.db\n",
    "collection=db.mars_hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url of page to be scraped\n",
    "url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "response5 = requests.get(url)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'lxml'\n",
    "soup5 = BeautifulSoup(response5.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup5.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
